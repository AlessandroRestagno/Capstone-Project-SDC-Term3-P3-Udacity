{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_output_path = \"D:\\\\Projects\\\\SDC\\\\Term3\\\\Capstone-Project-SDC-Term3-P3-Udacity\\\\site-recs\\\\final_train\"\n",
    "generator_train_path = \"D:\\\\Projects\\\\SDC\\\\Term3\\\\Capstone-Project-SDC-Term3-P3-Udacity\\\\site-recs\\\\generator_train\"\n",
    "generator_validation_path = \"D:\\\\Projects\\\\SDC\\\\Term3\\\\Capstone-Project-SDC-Term3-P3-Udacity\\\\site-recs\\\\generator_validation\"\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "# keras imports\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input as vgg16_preprocess\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input as vgg19_preprocess\n",
    "from keras.applications.xception import Xception, preprocess_input as xception_preprocess\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input as res_preprocess\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input as mobile_preprocess\n",
    "# from keras.applications.mobilenetv2 import MobileNetV2, mobile_v2_preprocess\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input as inception_preprocess\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Input, Dropout, Flatten, Dense, GlobalAveragePooling2D, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "\n",
    "# other imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import h5py\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the user configs\n",
    "with open('config.json') as f:    \n",
    "  config = json.load(f)\n",
    "\n",
    "# config variables\n",
    "model_name    = config[\"model\"]\n",
    "weights     = config[\"weights\"]\n",
    "include_top   = config[\"include_top\"]\n",
    "train_path    = config[\"train_path\"]\n",
    "features_path   = config[\"features_path\"]\n",
    "labels_path   = config[\"labels_path\"]\n",
    "test_size     = config[\"test_size\"]\n",
    "results     = config[\"results\"]\n",
    "model_path    = config[\"model_path\"]\n",
    "# num_classes   = config[\"num_classes\"]\n",
    "classifier_path = config[\"classifier_path\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.get_session().close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfg = K.tf.ConfigProto()\n",
    "cfg.gpu_options.allow_growth = True\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start time\n",
    "print (\"[STATUS] start time - {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")))\n",
    "start = time.time()\n",
    "print(f\"Model name: {model_name}\")\n",
    "\n",
    "# create the pretrained models\n",
    "# check for pretrained weight usage or not\n",
    "# check for top layers to be included or not\n",
    "if model_name == \"vgg16\":\n",
    "    base_model = VGG16(weights=weights)\n",
    "    model = Model(input=base_model.input, output=base_model.get_layer('fc1').output)\n",
    "    preprocess = vgg16_preprocess\n",
    "    image_size = (224, 224)\n",
    "elif model_name == \"vgg19\":\n",
    "    base_model = VGG19(weights=weights, include_top=False)\n",
    "#     model = Model(input=base_model.input, output=base_model.get_layer('fc1').output)\n",
    "    # Creating dictionary that maps layer names to the layers\n",
    "#     layer_dict = dict([(layer.name, layer) for layer in base_model.layers])\n",
    "\n",
    "#     # Getting output tensor of the last VGG layer that we want to include\n",
    "#     x = layer_dict['block2_pool'].output\n",
    "\n",
    "#     # Stacking a new simple convolutional network on top of it    \n",
    "#     x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)\n",
    "#     x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "#     x = Flatten()(x)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    preprocess = vgg19_preprocess\n",
    "    image_size = (224, 224)\n",
    "elif model_name == \"resnet50\":\n",
    "    base_model = ResNet50(weights=weights, include_top=include_top)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    preprocess = res_preprocess\n",
    "    image_size = (224, 224)\n",
    "elif model_name == \"inceptionv3\":\n",
    "    base_model = InceptionV3(include_top=include_top, weights=weights, input_tensor=Input(shape=(299,299,3)))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    preprocess = inception_preprocess\n",
    "    image_size = (299, 299)\n",
    "elif model_name == \"inceptionresnetv2\":\n",
    "    base_model = InceptionResNetV2(include_top=include_top, weights=weights, input_tensor=Input(shape=(299,299,3)))\n",
    "    model = Model(input=base_model.input, output=base_model.get_layer('custom').output)\n",
    "    image_size = (299, 299)\n",
    "elif model_name == \"mobilenet\":\n",
    "    base_model = MobileNet(include_top=include_top, weights=weights, input_tensor=Input(shape=(224,224,3)), input_shape=(224,224,3))\n",
    "    image_size = (224, 224)\n",
    "    preprocess = mobile_preprocess\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "elif model_name == \"mobilenetv2\":\n",
    "    base_model = MobileNetV2(include_top=include_top, weights=weights, input_tensor=Input(shape=(224,224,3)), input_shape=(224,224,3))  \n",
    "    image_size = (224, 224)\n",
    "    preprocess = mobile_v2_preprocess\n",
    "elif model_name == \"xception\":\n",
    "    base_model = Xception(weights=weights, include_top=include_top)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    image_size = (299, 299)\n",
    "    preprocess = xception_preprocess\n",
    "else:\n",
    "    base_model = None\n",
    "\n",
    "# Freeze the layers which you don't want to train.\n",
    "# for layer in base_model.layers[:5]:\n",
    "for layer in base_model.layers:    \n",
    "    layer.trainable = False\n",
    "\n",
    "x = Dense(512, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "\n",
    "predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(inputs = base_model.input, outputs = predictions)\n",
    "# for layer in model_final.layers:    \n",
    "#     print(layer.trainable)\n",
    "model_final.summary()\n",
    "\n",
    "# compile the model \n",
    "adam_optimizer = optimizers.Adam(lr=0.001)\n",
    "model_final.compile(\n",
    "    loss = \"categorical_crossentropy\", \n",
    "    #optimizer = optimizers.SGD(lr=0.0001, momentum=0.9, nesterov=True), \n",
    "    optimizer = adam_optimizer,\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "print (\"[INFO] successfully loaded base model and model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def rescale_preprocess(x, data_format=None, mode='caffe'):\n",
    "#     x = x[0:140 , 0:224, :]\n",
    "    x = cv2.resize(x, dsize=image_size, interpolation=cv2.INTER_CUBIC)\n",
    "    return preprocess(x, data_format, mode)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=rescale_preprocess,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = \"nearest\",\n",
    "    zoom_range = 0,\n",
    "    width_shift_range=0.02,\n",
    "    height_shift_range=0.05,\n",
    "    rotation_range=3,\n",
    "    validation_split=0.2)\n",
    "\n",
    "img_width, img_height = image_size[0], image_size[1]\n",
    "batch_size = 4\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    final_output_path, \n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "#     save_to_dir=generator_train_path,\n",
    "    shuffle=True,\n",
    "    subset='training')\n",
    "print(train_generator.class_indices)\n",
    "validation_generator  = datagen.flow_from_directory(\n",
    "    final_output_path, \n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "#     save_to_dir=generator_validation_path,\n",
    "    shuffle=True,\n",
    "    subset='validation')\n",
    "print(validation_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(model_name + \"_site.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(generator_train_path):\n",
    "    os.makedirs(generator_train_path)\n",
    "else:\n",
    "    output_file_list = glob.glob(os.path.join(generator_train_path, \"*.*\"))\n",
    "    for f in output_file_list:\n",
    "        os.remove(f)\n",
    "\n",
    "if not os.path.exists(generator_validation_path):\n",
    "    os.makedirs(generator_validation_path)\n",
    "else:\n",
    "    output_file_list = glob.glob(os.path.join(generator_validation_path, \"*.*\"))\n",
    "    for f in output_file_list:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "epochs = 100\n",
    "hist = model_final.fit_generator(\n",
    "    generator=train_generator,\n",
    "    epochs = epochs,\n",
    "    verbose = 1,\n",
    "    validation_data = validation_generator,\n",
    "    callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from random import shuffle\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "show_figures = False\n",
    "\n",
    "input_folder=\"D:/Projects/SDC/Term3/Capstone-Project-SDC-Term3-P3-Udacity/site-recs/final_train/green\"\n",
    "image_paths = glob.glob(os.path.join(input_folder, \"*.jpg\"))\n",
    "shuffle(image_paths)\n",
    "\n",
    "model_final.load_weights(model_name + \"_site.h5\")\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "nr_images = 1000\n",
    "\n",
    "rows = 20\n",
    "\n",
    "if show_figures:\n",
    "    fig, axes = plt.subplots(nrows=rows, ncols=1, figsize=(28, rows * 8))\n",
    "\n",
    "print (\"[INFO] program started on - \" + str(start_time))\n",
    "# labels = [list(train_generator.class_indices.keys())]\n",
    "labels = ['green', 'no', 'red']\n",
    "print(labels)\n",
    "\n",
    "bad_samples = 0\n",
    "for i, image_name in enumerate(image_paths[:nr_images]):\n",
    "    im = cv2.imread(image_name)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    im = im.astype(np.float32)\n",
    "    im = cv2.resize(im, image_size, interpolation = cv2.INTER_CUBIC)  \n",
    "    im = preprocess(im)\n",
    "    im = np.expand_dims(im, axis =0)\n",
    "    prob = model_final.predict(im)\n",
    "    probs = prob[0]\n",
    "#     print(probs)\n",
    "    j = np.argmax(prob,axis=1)[0]\n",
    "    \n",
    "    if j != 0:\n",
    "        if show_figures and bad_samples < rows:\n",
    "            img=mpimg.imread(image_name)\n",
    "            axes[bad_samples].imshow(img)\n",
    "            axes[bad_samples].set_title(f'Best guess: {labels[j]} with certainty {probs[j]}')\n",
    "        bad_samples += 1\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "time_diff = end_time - start_time\n",
    "print (f\"Time to run: {time_diff}\")\n",
    "\n",
    "print (\"Bad samples %: \" + str((float)(bad_samples) * 100 / nr_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
